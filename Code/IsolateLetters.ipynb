{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiAG_wLuVRld"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'image.png' # insert path to image here"
      ],
      "metadata": {
        "id": "FXGdcB1eWAYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_points(image_path):\n",
        "\n",
        "    img = Image.open(image_path).convert('L')\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    points = []\n",
        "    for y, row in enumerate(img_array):\n",
        "        for x, color in enumerate(row):\n",
        "            if color <= 100:\n",
        "                points.append((x, y))\n",
        "\n",
        "    return points\n",
        "\n",
        "points = np.array(image_to_points(path))"
      ],
      "metadata": {
        "id": "mYE8KZwSbgvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "sentence = DBSCAN(eps=40, min_samples=70).fit(points)\n",
        "sentence.labels_"
      ],
      "metadata": {
        "id": "vFsZ753A1Krb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(sentence.labels_))"
      ],
      "metadata": {
        "id": "I05HMSjp1wWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_labels = np.unique(sentence.labels_)"
      ],
      "metadata": {
        "id": "VoZVNUyL17-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_centers(clusters, labels, points):\n",
        "  centers = []\n",
        "  empty = 0\n",
        "  for i in range(len(labels)):\n",
        "    letter = points[clusters.labels_.ravel() == i]\n",
        "    if(len(letter) <= 0):\n",
        "      empty += 1\n",
        "      continue\n",
        "    centers.append(np.mean(letter[:, 0]))\n",
        "\n",
        "  num_centers = labels.shape[0] - empty\n",
        "  centers = np.array(centers).reshape(num_centers, 1)\n",
        "  index = np.arange(num_centers).reshape(num_centers, 1)\n",
        "  x_vals = np.append(centers, index, 1)\n",
        "  sorted_centers = x_vals[x_vals[:, 0].argsort()]\n",
        "\n",
        "  return sorted_centers"
      ],
      "metadata": {
        "id": "xZQ_apiUmHqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_img(image, target_size=(28, 28)):\n",
        "    img = cv2.bitwise_not(image)\n",
        "    kernel = np.ones((7, 7), np.uint8)  # Kernel size determines the thickness increase\n",
        "    img = cv2.dilate(img, kernel, iterations=1)\n",
        "    img = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
        "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "    img = img / 255.0\n",
        "    img = img.reshape(1, target_size[0], target_size[1], 1).astype('float32')\n",
        "    return img"
      ],
      "metadata": {
        "id": "whU-umJTtaPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_word(images, num_imgs=7):\n",
        "    fig, axes = plt.subplots(1, num_imgs, figsize=(7, 2))\n",
        "\n",
        "    for i in range(num_imgs):\n",
        "      img = preprocess_img(images[i])\n",
        "      img_reshaped = img.reshape(28, 28)\n",
        "      if(num_imgs == 1):\n",
        "        axes.imshow(img_reshaped, cmap='gray')\n",
        "        axes.axis('off')\n",
        "      else:\n",
        "        axes[i].imshow(img_reshaped, cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0q5FiJFoae8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word(word, model, word_points):\n",
        "  labels = np.unique(word.labels_)\n",
        "\n",
        "  sorted_centers = sort_centers(word, labels, word_points)\n",
        "  prediction = \"\"\n",
        "\n",
        "  images = []\n",
        "\n",
        "  for i in sorted_centers:\n",
        "    letter = word_points[word.labels_.ravel() == (i[1])]\n",
        "    min_x = int(min(letter[:, 0]))\n",
        "    range_x = int(max(letter[:, 0]) - min_x)\n",
        "    min_y = int(min(letter[:, 1]))\n",
        "    range_y = int(max(letter[:, 1]) - min_y)\n",
        "    dim = max(range_x, range_y)\n",
        "    padding = dim / 3\n",
        "    dim = int(max(range_x, range_y) + 2 * padding)\n",
        "    padding_x = int((dim - range_x) / 2)\n",
        "    padding_y = int((dim - range_y) / 2)\n",
        "    im = Image.new(mode = \"RGB\", size = (int(range_x) + 2 * padding_x, int(range_y) + 2 * padding_y), color = (255, 255, 255))\n",
        "\n",
        "    one_letter = np.array(im)\n",
        "\n",
        "    for point in letter:\n",
        "      one_letter[int(point[1] - min_y)][int(point[0]- min_x)] = [0, 0, 0]\n",
        "\n",
        "    blurred_letter = cv2.GaussianBlur(one_letter, (3, 3), 0)\n",
        "    img = Image.fromarray(blurred_letter, 'RGB')\n",
        "\n",
        "    square_im = Image.new(mode = \"RGB\", size = (dim, dim), color = (255, 255, 255))\n",
        "    square_im.paste(img, (padding_x, padding_y))\n",
        "    square_im = square_im.resize((128,128), resample = Image.LANCZOS)\n",
        "\n",
        "    arr = np.asarray(square_im)[:, :, 1]\n",
        "    images.append(arr)\n",
        "    preproc = preprocess_img(arr)\n",
        "\n",
        "    pred = model.predict(preproc)\n",
        "    letter_pred = chr(np.argmax(pred, axis=1)[0] + 65)\n",
        "    prediction += letter_pred\n",
        "\n",
        "  display_word(images, len(sorted_centers))\n",
        "  return prediction\n"
      ],
      "metadata": {
        "id": "Jpq7gYBZsLbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"hw_final.keras\")"
      ],
      "metadata": {
        "id": "4hKL54VKnZjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = sort_centers(sentence, sentence_labels, points)\n",
        "sentence_pred = \"\"\n",
        "for word in words[:,1]:\n",
        "  word_points = points[sentence.labels_.ravel() == (word)]\n",
        "  word_cluster = DBSCAN(eps=3, min_samples=10).fit(word_points)\n",
        "  pred = predict_word(word_cluster, model, word_points)\n",
        "  sentence_pred += pred + \" \"\n",
        "  print(pred + \" \")"
      ],
      "metadata": {
        "id": "0dpPMS87irLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_pred)"
      ],
      "metadata": {
        "id": "fohFSrD3qS5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}